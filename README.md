<<<<<<< HEAD

# Toxic Language Analysis

[![Website status](https://img.shields.io/website-up-down-green-red/https/chengb-2.github.io/CSE6242-Final-Project?label=Website%20status)](https://chengb-2.github.io/CSE6242-Final-Project/)

## ðŸ“ƒ DESCRIPTION

We will introduce our toxic language detection model which aims to detect whether a given statement \
implies stereotypes or social biases and provide detailed explanations for the implied harms.

The visualization website is based on d3.js.

## ðŸ”¨ INSTALLATION

### Option 1:

Click this [demo page](https://chengb-2.github.io/CSE6242-Final-Project/) and browse it on a website.

### Option 2:

Unzip the folder and follow the execution instruction.

## EXECUTION

1. Open up the console and change the directory to the folder directory.
2. Type `python3 -m http.server 8888` in the console and enter.
3. Go to `http://localhost:8888/code/`. (Chrome recommended)

## DEMO VIDEO

<!-- placeholder -->
